"""
ìƒì„±ëœ JSONL ë°ì´í„° ìƒ˜í”Œ í™•ì¸ ë° í†µê³„ ë¶„ì„
7ê°œ êµ¬ë‘ì  ë²„ì „
"""

import json
import tkinter as tk
from tkinter import filedialog
from pathlib import Path
from collections import Counter
import random
from tqdm import tqdm

# 7ê°œ êµ¬ë‘ì  ì •ì˜ (í•™ìŠµë°ì´í„° ìƒì„± ì½”ë“œì™€ ì¼ì¹˜)
punctuations = [
    ',', 'ã€‚', 'Â·', '?', '!', 'ã€Š', 'ã€‹'
]

def show_sample_reconstruction(jsonl_path: str, num_samples: int = 10) -> None:
    """JSONL ë°ì´í„°ì—ì„œ ìƒ˜í”Œì„ ë³µì›í•˜ì—¬ ë³´ì—¬ì£¼ê¸°"""
    print("\n" + "=" * 80)
    print("ğŸ“ í•™ìŠµë°ì´í„° ìƒ˜í”Œ í™•ì¸")
    print("=" * 80)

    # JSONL íŒŒì¼ì—ì„œ ëœë¤ ìƒ˜í”Œ ì¶”ì¶œ
    samples = []
    with open(jsonl_path, 'r', encoding='utf-8') as f:
        # ì „ì²´ ë¼ì¸ ìˆ˜ ê³„ì‚°
        total_lines = sum(1 for _ in f)

        # ë‹¤ì‹œ ì½ê¸°
        f.seek(0)

        # ëœë¤ ì¸ë±ìŠ¤ ìƒì„±
        if total_lines > num_samples:
            sample_indices = sorted(random.sample(range(total_lines), num_samples))
        else:
            sample_indices = list(range(total_lines))

        # ìƒ˜í”Œ ìˆ˜ì§‘
        for i, line in enumerate(f):
            if i in sample_indices:
                try:
                    samples.append((i, json.loads(line)))
                except json.JSONDecodeError as e:
                    print(f"ê²½ê³ : ì¤„ {i + 1} JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue

                if len(samples) >= num_samples:
                    break

    print(f"\nì´ {total_lines:,}ê°œ ì¤‘ {len(samples)}ê°œ ìƒ˜í”Œ í™•ì¸\n")

    # ì „ì²´ í†µê³„
    total_chars = 0
    total_puncts = 0
    all_punct_counter = Counter()

    # ê° ìƒ˜í”Œ ë³µì› ë° ì¶œë ¥
    for sample_idx, (line_no, sample) in enumerate(samples, 1):
        print(f"\n{'=' * 60}")
        print(f"ìƒ˜í”Œ #{sample_idx} (ì¤„ ë²ˆí˜¸: {line_no + 1:,})")
        print(f"{'=' * 60}")

        # ë°ì´í„° ì¶”ì¶œ
        chars = sample['c']
        compressed_labels = sample['l']
        length = sample['n']

        # 1. ì›ë³¸ í•œìë§Œ ì¶œë ¥
        print(f"\n1) ì›ë³¸ í•œì ({length}ì):")
        print(f"   {chars[:length]}")

        # 2. ë¼ë²¨ ì •ë³´ ì¶œë ¥ (êµ¬ë‘ì ì´ ìˆëŠ” ìœ„ì¹˜ë§Œ)
        punct_positions = []
        for i, indices in enumerate(compressed_labels[:length]):
            if indices:  # êµ¬ë‘ì ì´ ìˆëŠ” ê²½ìš°ë§Œ
                punct_list = [punctuations[idx] for idx in indices if 0 <= idx < len(punctuations)]
                punct_positions.append((i, chars[i], punct_list))

        if punct_positions:
            print(f"\n2) êµ¬ë‘ì  ìœ„ì¹˜ (ì´ {len(punct_positions)}ê³³):")
            for pos, char, puncts in punct_positions[:10]:  # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
                print(f"   ìœ„ì¹˜ {pos}: {char} â†’ {puncts}")
            if len(punct_positions) > 10:
                print(f"   ... ì™¸ {len(punct_positions) - 10}ê³³")

        # 3. ë³µì›ëœ í…ìŠ¤íŠ¸ (ì²˜ìŒ 100ìë§Œ)
        print(f"\n3) ë³µì›ëœ í…ìŠ¤íŠ¸:")
        reconstructed = ""
        display_length = min(100, length)
        for i in range(display_length):
            reconstructed += chars[i]
            if i < len(compressed_labels) and compressed_labels[i]:
                for idx in compressed_labels[i]:
                    if 0 <= idx < len(punctuations):
                        reconstructed += punctuations[idx]

        if length > 100:
            print(f"   {reconstructed}... (ì´ {length}ì)")
        else:
            print(f"   {reconstructed}")

        # 4. í†µê³„
        sample_puncts = sum(len(indices) for indices in compressed_labels[:length])
        total_chars += length
        total_puncts += sample_puncts

        print(f"\n4) ìƒ˜í”Œ í†µê³„:")
        print(f"   - í•œì ìˆ˜: {length}")
        print(f"   - êµ¬ë‘ì  ìˆ˜: {sample_puncts}")
        print(f"   - êµ¬ë‘ì  ë¹„ìœ¨: {sample_puncts / length:.2%}")
        print(f"   - ìµœëŒ€ ê¸¸ì´: {len(chars)} (íŒ¨ë”© í¬í•¨)")

        # 5. êµ¬ë‘ì  ë¶„í¬
        punct_counter = Counter()
        for indices in compressed_labels[:length]:
            for idx in indices:
                if 0 <= idx < len(punctuations):
                    punct_counter[punctuations[idx]] += 1
                    all_punct_counter[punctuations[idx]] += 1

        if punct_counter:
            print(f"\n5) ì´ ìƒ˜í”Œì˜ êµ¬ë‘ì  ë¶„í¬ (ìƒìœ„ 5ê°œ):")
            for punct, count in punct_counter.most_common(5):
                print(f"   {punct}: {count}íšŒ")

    # ì „ì²´ í†µê³„ ì¶œë ¥
    print(f"\n{'=' * 80}")
    print("ğŸ“Š ì „ì²´ ìƒ˜í”Œ í†µê³„")
    print(f"{'=' * 80}")
    print(f"ì´ {len(samples)}ê°œ ìƒ˜í”Œ ë¶„ì„:")
    print(f"- ì´ í•œì ìˆ˜: {total_chars:,}")
    print(f"- ì´ êµ¬ë‘ì  ìˆ˜: {total_puncts:,}")
    print(f"- í‰ê·  êµ¬ë‘ì  ë¹„ìœ¨: {total_puncts / total_chars:.2%}")

    if all_punct_counter:
        print(f"\nì „ì²´ êµ¬ë‘ì  ë¶„í¬:")
        for punct, count in all_punct_counter.most_common():
            print(f"  {punct}: {count:,}íšŒ ({count / total_puncts * 100:.1f}%)")

    # êµ¬ë‘ì  ì¸ë±ìŠ¤ í™•ì¸
    print(f"\nêµ¬ë‘ì  ì¸ë±ìŠ¤ ë§¤í•‘:")
    for i, punct in enumerate(punctuations):
        print(f"  {i:2d}: {punct}")

    # ì „ì²˜ë¦¬ ë°ì´í„°ì™€ ë¹„êµ (ìƒ˜í”Œ ê¸°ì¤€)
    if len(samples) >= 100:  # ìƒ˜í”Œì´ ì¶©ë¶„íˆ ë§ì„ ë•Œë§Œ
        compare_with_preprocessing_stats(all_punct_counter, total_puncts)


def load_preprocessing_stats():
    """ì „ì²˜ë¦¬ ë¶„ì„ íŒŒì¼ ë¡œë“œ"""
    root = tk.Tk()
    root.withdraw()

    print("\nì „ì²˜ë¦¬ ë¶„ì„ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì„ íƒ ì•ˆí•˜ë©´ í•˜ë“œì½”ë”©ëœ ê°’ ì‚¬ìš©)...")
    stats_path = filedialog.askopenfilename(
        title="ì „ì²˜ë¦¬ ë¶„ì„ txt íŒŒì¼ ì„ íƒ",
        filetypes=[("Text files", "*.txt")]
    )

    if not stats_path:
        # í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ê°’ ì‚¬ìš©
        print("ì „ì²˜ë¦¬ ë¶„ì„ íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return {
            ',': 38732510,
            'ã€‚': 10277924,
            'Â·': 2053592,
            '?': 1874165,
            'ã€‹': 49977,
            'ã€Š': 49971,
            '!': 19575
        }

    print(f"ì „ì²˜ë¦¬ ë¶„ì„ íŒŒì¼ ì½ëŠ” ì¤‘: {stats_path}")

    stats = {}
    try:
        with open(stats_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        # [êµ¬ë‘ì  ëª©ë¡] ì„¹ì…˜ ì°¾ê¸°
        in_punct_section = False
        for line in lines:
            line = line.strip()

            if '[êµ¬ë‘ì  ëª©ë¡]' in line:
                in_punct_section = True
                continue
            elif in_punct_section and line.startswith('['):
                # ë‹¤ë¥¸ ì„¹ì…˜ ì‹œì‘
                break
            elif in_punct_section and line and '(' in line and ':' in line:
                # êµ¬ë‘ì  ì •ë³´ íŒŒì‹±
                # ì˜ˆ: , (U+002C): 38,732,510íšŒ
                try:
                    punct_part = line.split('(')[0].strip()
                    count_part = line.split(':')[1].strip()
                    count = int(count_part.replace(',', '').replace('íšŒ', ''))

                    # êµ¬ë‘ì  ë¬¸ì ì¶”ì¶œ
                    if punct_part:
                        stats[punct_part] = count
                except Exception as e:
                    continue

        # ê³¡ì„  ë”°ì˜´í‘œ ì²˜ë¦¬ (íŒŒì¼ì—ì„œëŠ” ì‹¤ì œ ë¬¸ìë¡œ ì €ì¥ë¨)
        if "'" in stats:
            stats[chr(0x2018)] = stats.pop("'")
        if "'" in stats:
            stats[chr(0x2019)] = stats.pop("'")

        print(f"ì „ì²˜ë¦¬ ë¶„ì„ íŒŒì¼ì—ì„œ {len(stats)}ê°œ êµ¬ë‘ì  í†µê³„ ë¡œë“œ ì™„ë£Œ")

    except Exception as e:
        print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

    return stats


def compare_with_preprocessing_stats(all_punct_counter, total_puncts, preprocessing_stats=None):
    """ì „ì²˜ë¦¬ í†µê³„ì™€ ë¹„êµ"""
    print(f"\n{'=' * 80}")
    print("ğŸ“Š ì „ì²˜ë¦¬ ë°ì´í„°ì™€ ë¹„êµ")
    print(f"{'=' * 80}")

    if preprocessing_stats is None:
        preprocessing_stats = load_preprocessing_stats()
        if preprocessing_stats is None:
            print("ì „ì²˜ë¦¬ í†µê³„ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

    total_preprocessing = sum(preprocessing_stats.values())

    print("\nêµ¬ë‘ì ë³„ ë¹„êµ:")
    print(f"{'êµ¬ë‘ì ':^6} | {'ì „ì²˜ë¦¬ ë¹„ìœ¨':>12} | {'í•™ìŠµë°ì´í„° ë¹„ìœ¨':>15} | {'ì°¨ì´':>8}")
    print("-" * 60)

    for punct in punctuations:
        prep_count = preprocessing_stats.get(punct, 0)
        prep_ratio = prep_count / total_preprocessing * 100 if total_preprocessing > 0 else 0

        learn_count = all_punct_counter.get(punct, 0)
        learn_ratio = learn_count / total_puncts * 100 if total_puncts > 0 else 0

        diff = abs(prep_ratio - learn_ratio)

        # ì°¨ì´ê°€ í° ê²½ìš° ê°•ì¡°
        flag = "âš ï¸" if diff > 1.0 else "âœ…"

        print(f"{punct:^6} | {prep_ratio:>11.2f}% | {learn_ratio:>14.2f}% | {diff:>7.2f}% {flag}")

    # ì „ì²´ í†µê³„ ë¹„êµ
    print(f"\nì „ì²´ í†µê³„:")
    print(f"- ì „ì²˜ë¦¬ ì´ êµ¬ë‘ì : {total_preprocessing:,}")
    print(f"- í•™ìŠµë°ì´í„° ìƒ˜í”Œ êµ¬ë‘ì : {total_puncts:,}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # íŒŒì¼ ì„ íƒ
    root = tk.Tk()
    root.withdraw()

    print("ìƒì„±ëœ JSONL íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”...")
    jsonl_path = filedialog.askopenfilename(
        title="train.jsonl ë˜ëŠ” val.jsonl ì„ íƒ",
        filetypes=[("JSONL files", "*.jsonl")]
    )

    if not jsonl_path:
        print("íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    print(f"\nì„ íƒëœ íŒŒì¼: {jsonl_path}")

    # ì „ì²´ íŒŒì¼ ë¶„ì„í• ì§€ ìƒ˜í”Œë§Œ ë³¼ì§€ ì„ íƒ
    analysis_type = input("\në¶„ì„ ìœ í˜• ì„ íƒ:\n1. ìƒ˜í”Œë§Œ í™•ì¸ (ë¹ ë¦„)\n2. ì „ì²´ íŒŒì¼ í†µê³„ ë¶„ì„ (ëŠë¦¼)\nì„ íƒ [1/2]: ")

    if analysis_type == "2":
        # ì „ì²´ íŒŒì¼ í†µê³„ ë¶„ì„
        analyze_full_statistics(jsonl_path)
    else:
        # ìƒ˜í”Œ ê°œìˆ˜ ì…ë ¥
        try:
            num_samples = int(input("\ní™•ì¸í•  ìƒ˜í”Œ ê°œìˆ˜ (ê¸°ë³¸ê°’ 10): ") or "10")
        except ValueError:
            num_samples = 10

        # ìƒ˜í”Œ í™•ì¸
        show_sample_reconstruction(jsonl_path, num_samples)

    print("\n\nâœ… ë¶„ì„ ì™„ë£Œ!")


def analyze_full_statistics(jsonl_path: str) -> None:
    """ì „ì²´ íŒŒì¼ì˜ êµ¬ë‘ì  í†µê³„ ë¶„ì„"""
    print(f"\nì „ì²´ íŒŒì¼ ë¶„ì„ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

    total_chars = 0
    total_puncts = 0
    punct_counter = Counter()
    line_count = 0

    with open(jsonl_path, 'r', encoding='utf-8') as f:
        for line in tqdm(f, desc="ë¶„ì„ ì¤‘"):
            line_count += 1

            try:
                sample = json.loads(line)
                length = sample['n']
                total_chars += length

                # êµ¬ë‘ì  ì¹´ìš´íŠ¸
                for indices in sample['l'][:length]:
                    for idx in indices:
                        if 0 <= idx < len(punctuations):
                            punct_counter[punctuations[idx]] += 1
                            total_puncts += 1

            except Exception as e:
                if line_count % 10000 == 0:  # ì—ëŸ¬ê°€ ë„ˆë¬´ ë§ì´ ì¶œë ¥ë˜ì§€ ì•Šë„ë¡
                    print(f"ê²½ê³ : ì¤„ {line_count} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                continue

    print(f"\n{'=' * 80}")
    print("ğŸ“Š ì „ì²´ íŒŒì¼ í†µê³„")
    print(f"{'=' * 80}")
    print(f"- ì´ ë¼ì¸ ìˆ˜: {line_count:,}")
    print(f"- ì´ í•œì ìˆ˜: {total_chars:,}")
    print(f"- ì´ êµ¬ë‘ì  ìˆ˜: {total_puncts:,}")
    print(f"- í‰ê·  êµ¬ë‘ì  ë¹„ìœ¨: {total_puncts / total_chars:.3f} (í•œìë‹¹)")

    print(f"\nêµ¬ë‘ì  ë¶„í¬:")
    for punct, count in punct_counter.most_common():
        print(f"  {punct}: {count:,}íšŒ ({count / total_puncts * 100:.2f}%)")

    # ì „ì²˜ë¦¬ ë°ì´í„°ì™€ ë¹„êµ
    compare_with_preprocessing_stats(punct_counter, total_puncts)

    # êµ¬ë‘ì  ìˆ˜ ì°¨ì´ ì„¤ëª… ì¶”ê°€
    print(f"\n{'=' * 80}")
    print("ğŸ’¡ êµ¬ë‘ì  ìˆ˜ ì°¨ì´ ì„¤ëª…")
    print(f"{'=' * 80}")

    # íŒŒì¼ëª…ì—ì„œ train/val êµ¬ë¶„
    file_name = Path(jsonl_path).name
    if 'train' in file_name:
        print("\nâš ï¸  í˜„ì¬ train.jsonlë§Œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.")
        print("   ì „ì²´ ë°ì´í„°ì˜ ì•½ 90%ë§Œ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        print("   ì •í™•í•œ ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” val.jsonlë„ í•¨ê»˜ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.")
    elif 'val' in file_name:
        print("\nâš ï¸  í˜„ì¬ val.jsonlë§Œ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.")
        print("   ì „ì²´ ë°ì´í„°ì˜ ì•½ 10%ë§Œ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")

    print("\nì „ì²˜ë¦¬ ë°ì´í„°ì™€ ì°¨ì´ê°€ ë‚˜ëŠ” ì´ìœ :")
    print("1. ì˜¤ë²„ë©(overlap=50)ìœ¼ë¡œ ì¸í•œ ë°ì´í„° ì¦ê°€")
    print("   - 512ìë³´ë‹¤ ê¸´ í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ ì²­í¬ë¡œ ë¶„í• ")
    print("   - ì²­í¬ ê°„ 50ìì”© ê²¹ì¹˜ë©´ì„œ ì¼ë¶€ êµ¬ë‘ì  ì¤‘ë³µ ì¹´ìš´íŠ¸")
    print("2. ì˜ˆì œ ìˆ˜: ì•½ 8.86% ì¦ê°€")
    print("3. êµ¬ë‘ì  ìˆ˜: ì•½ 3-4% ì¦ê°€ ì˜ˆìƒ")

if __name__ == "__main__":
    main()