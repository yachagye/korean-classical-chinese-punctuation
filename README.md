# Korean Classical Chinese Punctuation Prediction Model
# í•œêµ­ ê³ ì „í•œë¬¸ êµ¬ë‘ì  ì˜ˆì¸¡ ëª¨ë¸

[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![GitHub](https://img.shields.io/badge/GitHub-yachagye-181717?logo=github)](https://github.com/yachagye/korean-classical-chinese-punctuation)
[![DOI](https://img.shields.io/badge/DOI-10.37924/JSSW.100.9-blue)](https://doi.org/10.37924/JSSW.100.9)

[English](#english) | [í•œêµ­ì–´](#korean)

---

## <a id="korean"></a>í•œêµ­ì–´

### ê°œìš”

í•œêµ­ ê³ ì „ í•œë¬¸ í…ìŠ¤íŠ¸ì— ìë™ìœ¼ë¡œ êµ¬ë‘ì ì„ ì˜ˆì¸¡í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤. ì„ í–‰ ì—°êµ¬ë¥¼ í†µí•´ ì¶•ì ëœ êµê°í‘œì  í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•˜ì—¬ 7ì¢…ì˜ êµ¬ë‘ì ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

**ì£¼ìš” í™œìš© ë¶„ì•¼**:
- í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë° ì •ê·œí™”
- ìƒ‰ì¸Â·ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶•
- ë²ˆì—­ ì „ì²˜ë¦¬
- OCR í›„ì²˜ë¦¬
- ë””ì§€í„¸ ì¸ë¬¸í•™ ì—°êµ¬

### ì£¼ìš” íŠ¹ì§•

- **ë†’ì€ ì •í™•ë„**: F1 Score 0.9110 (v2)
- **ëŒ€ê·œëª¨ í•™ìŠµ**: 4ì–µ 2ì²œë§Œ ì, 340ë§Œ ê°œ ìƒ˜í”Œ
- **7ì¢… êµ¬ë‘ì **: , ã€‚ Â· ? ! ã€Š ã€‹
- **ë„ë©”ì¸ íŠ¹í™”**: ì—°ëŒ€ê¸°, ë“±ë¡, ì¼ê¸°, ë¬¸ì§‘ ë“± ë‹¤ì–‘í•œ ì¥ë¥´ ì§€ì›
- **ì¦‰ì‹œ ì‚¬ìš©**: GUI ì‹¤í–‰íŒŒì¼ ì œê³µ

### ëª¨ë¸ ë²„ì „

| ë²„ì „ | ì‚¬ì „í•™ìŠµ ëª¨ë¸ | F1 Score | ë¹„ê³  |
|------|--------------|----------|------|
| **v2** | SikuRoBERTa (`SIKU-BERT/sikuroberta`) | **0.9110** | ìµœì‹  ê¶Œì¥ |
| v1 | Chinese-RoBERTa (`hfl/chinese-roberta-wwm-ext`) | 0.9050 | ë…¼ë¬¸ ê²Œì¬ ë²„ì „ |

### ì„±ëŠ¥

**ì „ì²´ ì„±ëŠ¥**

| ë²„ì „ | F1 Score | Precision | Recall |
|------|----------|-----------|--------|
| **v2** | **0.9110** | 0.9117 | 0.9103 |
| v1 | 0.9050 | 0.9057 | 0.9043 |

**êµ¬ë‘ì ë³„ ì„±ëŠ¥ (v1)**

| êµ¬ë‘ì  | F1 Score | Precision | Recall |
|--------|----------|-----------|--------|
| ? | 0.9436 | 0.9419 | 0.9454 |
| , | 0.9127 | 0.9130 | 0.9124 |
| ã€‚ | 0.8818 | 0.9054 | 0.8594 |
| Â· | 0.8759 | 0.9157 | 0.8394 |
| ã€Š | 0.7367 | 0.8155 | 0.6717 |
| ã€‹ | 0.7311 | 0.8024 | 0.6713 |
| ! | 0.6369 | 0.8114 | 0.5241 |

*v2 êµ¬ë‘ì ë³„ ìƒì„¸ ì„±ëŠ¥ì€ ì¶”í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •*

**ë„ë©”ì¸ë³„ ì„±ëŠ¥ (v1)**

| ë„ë©”ì¸ | F1 Score | ë°ì´í„° ê·œëª¨(ì´ ë¬¸ì ìˆ˜) |
|--------|----------|------|
| ì—°ëŒ€ê¸° | 0.9162 | 30,682,976 |
| ë“±ë¡ | 0.9114 | 1,896,232 |
| ì§€ë¦¬ì§€ | 0.9116 | 501,942 |
| ì „ê¸° | 0.8606 | 591,983 |
| ë²•ë ¹ | 0.8485 | 907,893 |
| ë¬¸ì§‘ | 0.8354 | 1,885,268 |
| ì¼ê¸° | 0.8229 | 544,768 |

**ì™¸ë¶€ ê²€ì¦ (ë¯¸í•™ìŠµ ë°ì´í„°, v1)**

ê³ ë¦¬ì ë§Œ ì§€ì •ëœ ë¯¸í•™ìŠµ ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ í‘œì  ìœ„ì¹˜ ì¼ì¹˜ ì„±ëŠ¥ í‰ê°€:

| ë°ì´í„°ì…‹ | F1 Score | ë°ì´í„° ê·œëª¨(ì´ ë¬¸ì ìˆ˜) | ì¶œì²˜ |
|---------|----------|------|------|
| í•œêµ­ë¬¸ì§‘ì´ê°„ | 0.8784 | 166,763,095 | ê³ ì „ì¢…í•©DB |
| ì¼ì„±ë¡ | 0.9065 | 6,743,710 | ê·œì¥ê°í•œêµ­í•™ì—°êµ¬ì› |

### ğŸ“¦ ë°ì´í„° ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

**Google Drive ê³µê°œ ì €ì¥ì†Œ**: https://drive.google.com/drive/folders/1WGueOa8Oz7kqv4ha7_9pgFRKOzXWId2H?usp=drive_link

#### í´ë” êµ¬ì¡°

```
í•œêµ­ ê³ ì „í•œë¬¸ êµ¬ë‘ì  ì˜ˆì¸¡ ëª¨ë¸/
â”‚
â”œâ”€â”€ ì „ì²˜ë¦¬ í…ìŠ¤íŠ¸/              # ì „ì²˜ë¦¬ ì™„ë£Œ í…ìŠ¤íŠ¸ (í‘œì  â—‹, ZIP)
â”‚   â”œâ”€â”€ ê¸°íƒ€.zip
â”‚   â”œâ”€â”€ ë“±ë¡.zip               
â”‚   â”œâ”€â”€ ë¬¸ì§‘.zip                
â”‚   â”œâ”€â”€ ë²•ë ¹.zip                
â”‚   â”œâ”€â”€ ì—°ëŒ€ê¸°.zip              
â”‚   â”œâ”€â”€ ì¼ê¸°.zip              
â”‚   â”œâ”€â”€ ì „ê¸°.zip                
â”‚   â””â”€â”€ ì§€ë¦¬ì§€.zip             
â”‚
â”œâ”€â”€ í•™ìŠµ ë°ì´í„°/                # ì „ì²˜ë¦¬ ì™„ë£Œ JSONL (ZIP)
â”‚   â”œâ”€â”€ train.zip              # í•™ìŠµ ë°ì´í„°
â”‚   â””â”€â”€ val.zip                # ê²€ì¦ ë°ì´í„°
â”‚
â”œâ”€â”€ ëª¨ë¸(.ckpt)/               # í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ best_model_9050.zip    # v1: F1 0.9050 (ë…¼ë¬¸ ë²„ì „)
â”‚   â””â”€â”€ best_model_9110.zip    # v2: F1 0.9110 (ìµœì‹  ê¶Œì¥)
â”‚
â”œâ”€â”€ ì½”ë“œ/                      # ì „ì²´ ì†ŒìŠ¤ì½”ë“œ
â”‚   â”œâ”€â”€ [ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸]
â”‚   â”‚   â”œâ”€â”€ 1_1_ì „ì²˜ë¦¬_í•œê¸€,ê°€ë‚˜,ìˆ«ìí–‰ ì œê±°.py
â”‚   â”‚   â”œâ”€â”€ 1_2_ì „ì²˜ë¦¬_êµ¬ë‘ì  ë³€í™˜ 26ì¢….py
â”‚   â”‚   â”œâ”€â”€ 1_3_ì „ì²˜ë¦¬_í•œì,êµ¬ë‘ì  26ì¢… ë³´ì¡´, ê¸°íƒ€...
â”‚   â”‚   â”œâ”€â”€ 1_4_ì „ì²˜ë¦¬_êµ¬ë‘ì  ë³€í™˜ 7ì¢….py
â”‚   â”‚   â”œâ”€â”€ 1_5_ì „ì²˜ë¦¬_êµ¬ë‘ì  ì—†ëŠ” í–‰ ì œê±°_7ì¢….py
â”‚   â”‚   â””â”€â”€ 1_6_ì „ì²˜ë¦¬_êµ¬ë‘ì  ì¤‘ë³µ ì œê±°_7ì¢….py
â”‚   â”‚
â”‚   â”œâ”€â”€ [í•™ìŠµ ë°ì´í„° ìƒì„±]
â”‚   â”‚   â”œâ”€â”€ 2_í•™ìŠµë°ì´í„°ìƒì„±_êµ¬ë‘ì 7_jsonl.py
â”‚   â”‚   â””â”€â”€ 3_í•™ìŠµë°ì´í„°_ê²€ì¦_êµ¬ë‘ì 7_jsonl.py
â”‚   â”‚
â”‚   â”œâ”€â”€ [ëª¨ë¸ í•™ìŠµ ë° í‰ê°€]
â”‚   â”‚   â”œâ”€â”€ 4_0_êµ¬ë‘ì _í•™ìŠµ_v1_êµ¬ë‘ì 7_ChineseRoBERTa_Lightning.py
â”‚   â”‚   â”œâ”€â”€ 4_0_êµ¬ë‘ì _í•™ìŠµ_v2_êµ¬ë‘ì 7_SikuRoBERTa_Lightning.py
â”‚   â”‚   â””â”€â”€ 6_F1 í‰ê°€.py
â”‚   â”‚
â”‚   â””â”€â”€ [ì¶”ë¡  ë° í™œìš©]
â”‚       â”œâ”€â”€ êµ¬ë‘ì 7_ì¶”ë¡ ëª¨ë¸.py        # í•µì‹¬ ì¶”ë¡  ëª¨ë“ˆ
â”‚       â”œâ”€â”€ êµ¬ë‘ì 7_ì§€ì •_txt.py       # TXT íŒŒì¼ ì²˜ë¦¬
â”‚       â”œâ”€â”€ êµ¬ë‘ì 7_ì§€ì •_csv.py       # CSV íŒŒì¼ ì²˜ë¦¬
â”‚       â”œâ”€â”€ êµ¬ë‘ì 7_ê²€ì¦_ìœ„ì¹˜ì •í™•ë„.py
â”‚       â”œâ”€â”€ êµ¬ë‘ì _ì§€ì •_ì‹¤í–‰íŒŒì¼_ë¹Œë“œ_v1_ChineseRoBERTa.py
â”‚       â””â”€â”€ êµ¬ë‘ì _ì§€ì •_ì‹¤í–‰íŒŒì¼_ë¹Œë“œ_v2_SikuRoBERTa.py
â”‚
â””â”€â”€ í•œêµ­ ê³ ì „í•œë¬¸ êµ¬ë‘ì  ì˜ˆì¸¡ í”„ë¡œê·¸ë¨ v1.0/
    â”œâ”€â”€ README_v1.0.txt                    # ì‚¬ìš© ì„¤ëª…ì„œ
    â””â”€â”€ í•œë¬¸êµ¬ë‘ì ì¶”ë¡ _v1.0.zip             # Windows ì‹¤í–‰íŒŒì¼
        â””â”€â”€ í•œë¬¸êµ¬ë‘ì ì¶”ë¡ .exe
    â”œâ”€â”€ README_v2.0.txt                    # ì‚¬ìš© ì„¤ëª…ì„œ
    â””â”€â”€ í•œë¬¸êµ¬ë‘ì ì¶”ë¡ _v2.0.zip             # Windows ì‹¤í–‰íŒŒì¼
        â””â”€â”€ í•œë¬¸êµ¬ë‘ì ì¶”ë¡ _v2.exe
```

#### ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ

**1. ì‹¤í–‰íŒŒì¼ë§Œ í•„ìš”í•œ ê²½ìš° (ì¼ë°˜ ì‚¬ìš©ì)**
```
ğŸ“¥ ë‹¤ìš´ë¡œë“œ: í•œêµ­ ê³ ì „í•œë¬¸ êµ¬ë‘ì  ì˜ˆì¸¡ í”„ë¡œê·¸ë¨/í•œë¬¸êµ¬ë‘ì ì¶”ë¡ _v2.0.zip (v2 ê¶Œì¥)
ğŸ“¦ í¬ê¸°: ì•½ 3.6GB
ğŸ’» ìš©ë„: Windowsì—ì„œ ë°”ë¡œ ì‹¤í–‰ (Python ë¶ˆí•„ìš”)
```

**2. Python ì½”ë“œ ì‹¤í–‰ (ê°œë°œì)**
```
ğŸ“¥ ë‹¤ìš´ë¡œë“œ: 
   - ì½”ë“œ/ í´ë” ì „ì²´
   - ëª¨ë¸(.ckpt)/best_model_9110.zip (v2 ê¶Œì¥)
ğŸ’» ì‚¬ìš©ë²•:
   python êµ¬ë‘ì 7_ì§€ì •_txt.py --checkpoint checkpoint.ckpt --input your_file.txt
```

**3. ëª¨ë¸ í•™ìŠµ/ì—°êµ¬ (AI ì—°êµ¬ì)**
```
ğŸ“¥ ë‹¤ìš´ë¡œë“œ:
   - í•™ìŠµ ë°ì´í„°/train.zip, val.zip
   - ì½”ë“œ/4_0_êµ¬ë‘ì _í•™ìŠµ_v1_êµ¬ë‘ì 7_ChineseRoBERTa_Lightning.py (v1)
   - ì½”ë“œ/4_0_êµ¬ë‘ì _í•™ìŠµ_v2_êµ¬ë‘ì 7_SikuRoBERTa_Lightning.py (v2)
   - ëª¨ë¸(.ckpt)/ (ë¯¸ì„¸ì¡°ì • ì‹œ)
ğŸ’» ìš©ë„: ëª¨ë¸ ì¬í•™ìŠµ, ë¯¸ì„¸ì¡°ì •, ì‹¤í—˜
```

**4. ì›ë³¸ í…ìŠ¤íŠ¸ ì—°êµ¬ (ì—­ì‚¬í•™ì/ì¸ë¬¸í•™ì)**
```
ğŸ“¥ ë‹¤ìš´ë¡œë“œ: ì „ì²˜ë¦¬ í…ìŠ¤íŠ¸/ í´ë” (í•„ìš”í•œ ZIPë§Œ)
ğŸ’» ìš©ë„: ë°ì´í„° ë¶„ì„, ì½”í¼ìŠ¤ êµ¬ì¶•, ë‹¤ë¥¸ ì—°êµ¬ í™œìš©
```

**5. ì™„ì „ ì¬í˜„ (Full Reproduction)**
```
ğŸ“¥ ë‹¤ìš´ë¡œë“œ: ì „ì²´ í´ë”
ğŸ’» ìš©ë„: ì›ë³¸ ë°ì´í„°ë¶€í„° ëª¨ë¸ ë°°í¬ê¹Œì§€ ì „ ê³¼ì • ì¬í˜„
ğŸ“ ê³¼ì •:
   1. ì „ì²˜ë¦¬ í…ìŠ¤íŠ¸/ ì••ì¶• í•´ì œ
   2. ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ 6ë‹¨ê³„ ì‹¤í–‰
   3. í•™ìŠµ ë°ì´í„° ìƒì„± (JSONL)
   4. ëª¨ë¸ í•™ìŠµ (Lightning)
   5. í‰ê°€ ë° ê²€ì¦
```

#### í•™ìŠµ ë°ì´í„° ìƒì„¸ ì •ë³´

**train.zip ì••ì¶• í•´ì œ ì‹œ**: `train.jsonl` (ì•½ 2.5GB)
- ìƒ˜í”Œ ìˆ˜: ì•½ 340ë§Œ ê°œ
- ì´ ë¬¸ì ìˆ˜: ì•½ 4ì–µ 2ì²œë§Œ ì
- í˜•ì‹: JSONL (í•œ ì¤„ì— í•œ ìƒ˜í”Œ)

**JSONL êµ¬ì¡° ì˜ˆì‹œ**:
```json
{
  "text": "å¤ªç¥–åº·ç»å¤§ç‹å§“æè«±æˆæ¡‚å­—å›æ™‰",
  "labels": [
    [0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0],
    [1,0,0,0,0,0,0],
    ...
  ],
  "length": 15,
  "source": "ì¡°ì„ ì™•ì¡°ì‹¤ë¡",
  "domain": "ì‹¤ë¡"
}
```

**labels ì¸ë±ìŠ¤**: [,  ã€‚ Â· ? ! ã€Š ã€‹]
- ì˜ˆ: `[1,0,0,0,0,0,0]` = ì‰¼í‘œ(,)
- ì˜ˆ: `[0,1,0,0,0,0,0]` = ë§ˆì¹¨í‘œ(ã€‚)

#### ì›ë³¸ í…ìŠ¤íŠ¸ ZIP íŒŒì¼ ì •ë³´

| ZIP íŒŒì¼ | ì••ì¶• í•´ì œ í›„ | ì£¼ìš” ë¬¸í—Œ | 
|----------|-------------|----------|
| ì—°ëŒ€ê¸°.zip | ~2GB | ì¡°ì„ ì™•ì¡°ì‹¤ë¡ ë“± | 
| ë“±ë¡.zip | ~1.5GB | ê°ì‚¬ë“±ë¡ | 
| ì¼ê¸°.zip | ~1.2GB | ë¬µì¬ì¼ê¸° ë“± | 
| ë¬¸ì§‘.zip | ~1GB | í•œêµ­ë¬¸ì§‘ì´ê°„ | 
| ë²•ë ¹.zip | ~500MB | ê²½êµ­ëŒ€ì „ ë“± | 
| ì§€ë¦¬ì§€.zip | ~300MB | ëŒ€ë™ì§€ì§€ ë“± | 
| ì „ê¸°.zip | ~200MB | êµ­ì¡°ì¸ë¬¼ê³  ë“± | 
| ê¸°íƒ€.zip | ~100MB |  | 

- **ì••ì¶• í˜•ì‹**: UTF-8 ì¸ì½”ë”© TXT íŒŒì¼
- **êµ¬ë‘ì **: ì›ë³¸ êµê°í‘œì  (26ì¢… â†’ ì „ì²˜ë¦¬ í›„ 7ì¢…ìœ¼ë¡œ ë³€í™˜)

### ë¹ ë¥¸ ì‹œì‘

#### ë°©ë²• 1: Windows ì‹¤í–‰ íŒŒì¼ (ê¶Œì¥ - ì¼ë°˜ ì‚¬ìš©ì)

```
1. Google Driveì—ì„œ "í•œë¬¸êµ¬ë‘ì ì¶”ë¡ .exe" ë‹¤ìš´ë¡œë“œ
2. ZIP ì••ì¶• í•´ì œ
3. í•œë¬¸êµ¬ë‘ì ì¶”ë¡ .exe ì‹¤í–‰
4. GUIì—ì„œ íŒŒì¼ ì„ íƒ â†’ ì²˜ë¦¬ ì‹œì‘
```

**ë‹¤ìš´ë¡œë“œ ë§í¬**: [Google Drive](https://drive.google.com/drive/folders/1WGueOa8Oz7kqv4ha7_9pgFRKOzXWId2H?usp=drive_link)

#### ë°©ë²• 2: Python ì½”ë“œ ì‹¤í–‰ (ê°œë°œì/ì—°êµ¬ì)

**Python ì½”ë“œ**

```python
from êµ¬ë‘ì 7_ì¶”ë¡ ëª¨ë¸ import PunctuationPredictor

# ëª¨ë¸ ë¡œë“œ
predictor = PunctuationPredictor(
    checkpoint_path="path/to/checkpoint.ckpt"
)

# ì˜ˆì¸¡
text = "å¤ªç¥–åº·ç»å¤§ç‹å§“æè«±æˆæ¡‚å­—å›æ™‰å¤è«±æ—¦è™Ÿæ¾è»’"
result = predictor.predict(text)
print(result)
# ì¶œë ¥: å¤ªç¥–åº·ç»å¤§ç‹, å§“æ, è«±æˆæ¡‚, å­—å›æ™‰ã€‚å¤è«±æ—¦, è™Ÿæ¾è»’ã€‚
```

**GUI ì‹¤í–‰íŒŒì¼**

```bash
# Windowsìš© ì‹¤í–‰íŒŒì¼ ë¹Œë“œ (v1)
python êµ¬ë‘ì _ì§€ì •_ì‹¤í–‰íŒŒì¼_ë¹Œë“œ_v1_ChineseRoBERTa.py

# Windowsìš© ì‹¤í–‰íŒŒì¼ ë¹Œë“œ (v2)
python êµ¬ë‘ì _ì§€ì •_ì‹¤í–‰íŒŒì¼_ë¹Œë“œ_v2_SikuRoBERTa.py

# ì‹¤í–‰
./dist/í•œë¬¸êµ¬ë‘ì ì¶”ë¡ .exe
```

### í•™ìŠµ ë°ì´í„°

**ì¶œì²˜**
- êµ­ì‚¬í¸ì°¬ìœ„ì›íšŒ í•œêµ­ì‚¬ë°ì´í„°ë² ì´ìŠ¤(https://db.history.go.kr/)
- í•œêµ­ê³ ì „ì¢…í•©DB(https://db.itkc.or.kr/)
- í•œêµ­í•™ì¤‘ì•™ì—°êµ¬ì› ë””ì§€í„¸ì¥ì„œê°(https://jsg.aks.ac.kr/)

**ê·œëª¨**
- ì´ ë¬¸ì ìˆ˜: ì•½ 4ì–µ 2ì²œë§Œ ì
- í•™ìŠµ ìƒ˜í”Œ: ì•½ 340ë§Œ ê°œ
- ë°ì´í„° ìœ í˜•: 8ê°œ ì¥ë¥´ (ì—°ëŒ€ê¸°, ë¬¸ì§‘, ì¼ê¸°, ë“±ë¡, ë²•ë ¹, ì§€ë¦¬ì§€, ì „ê¸° ë“±)
- êµ¬ë‘ì  ì¢…ë¥˜: 7ì¢… (, ã€‚ Â· ? ! ã€Š ã€‹)

**ì „ì²˜ë¦¬**
- êµê°í‘œì  í…ìŠ¤íŠ¸ ìˆ˜ì§‘Â·ì •ì œ
- 7ì¢… í‘œì ìœ¼ë¡œ í‘œì¤€í™”
- 6ë‹¨ê³„ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

### ëª¨ë¸ ì•„í‚¤í…ì²˜

**v2 (ìµœì‹  ê¶Œì¥)**
- **Base Model**: SikuRoBERTa (`SIKU-BERT/sikuroberta`)
- **Task**: Multi-label Classification
- **Labels**: 7 punctuation marks
- **Training**:
  - GPU: L40S 48GB
  - Batch Size: 160 (effective)
  - Learning Rate: 2e-5
  - Epochs: 3
  - Mixed Precision: bf16

**v1 (ë…¼ë¬¸ ê²Œì¬ ë²„ì „)**
- **Base Model**: Chinese-RoBERTa (`hfl/chinese-roberta-wwm-ext`)
- ê¸°íƒ€ ì„¤ì • ë™ì¼

### ë””ë ‰í† ë¦¬ êµ¬ì¡°
```
korean-classical-chinese-punctuation/
â”œâ”€â”€ preprocessing/           # ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ (1_1 ~ 1_6)
â”œâ”€â”€ data_generation/         # í•™ìŠµ ë°ì´í„° ìƒì„± (2, 3)
â”œâ”€â”€ training/                # ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (4_0, 6)
â”œâ”€â”€ inference/               # ì¶”ë¡  ë° í™œìš© (êµ¬ë‘ì 7_*)
â””â”€â”€ build/                   # ì‹¤í–‰íŒŒì¼ ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
```

### ì¸ìš©

ì´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì‹œëŠ” ê²½ìš° ë‹¤ìŒê³¼ ê°™ì´ ì¸ìš©í•´ì£¼ì„¸ìš”:

**APA ìŠ¤íƒ€ì¼:**
```
ì–‘ì •í˜„ (2025). ë”¥ëŸ¬ë‹ ê¸°ë°˜ í•œêµ­ ê³ ì „í•œë¬¸ í‘œì  ì¶”ë¡  ìë™í™” ëª¨ë¸ì˜ êµ¬ì¶•ê³¼ í™œìš©. 
ì—­ì‚¬í•™ì—°êµ¬, 100, 267-297. https://doi.org/10.37924/JSSW.100.9
```

**BibTeX:**
```bibtex
@article{yang2025punctuation,
  title={ë”¥ëŸ¬ë‹ ê¸°ë°˜ í•œêµ­ ê³ ì „í•œë¬¸ í‘œì  ì¶”ë¡  ìë™í™” ëª¨ë¸ì˜ êµ¬ì¶•ê³¼ í™œìš©},
  author={ì–‘ì •í˜„},
  journal={ì—­ì‚¬í•™ì—°êµ¬},
  volume={100},
  pages={267--297},
  year={2025},
  publisher={í˜¸ë‚¨ì‚¬í•™íšŒ},
  doi={10.37924/JSSW.100.9}
}
```

**ë…¼ë¬¸ ì •ë³´:**
- ì €ë„: ì—­ì‚¬í•™ì—°êµ¬ (The Korean Journal of History)
- ê¶Œí˜¸: 100í˜¸
- ë°œí–‰: 2025ë…„ 11ì›” 30ì¼
- ì¶œíŒì‚¬: í˜¸ë‚¨ì‚¬í•™íšŒ
- DOI: [10.37924/JSSW.100.9](https://doi.org/10.37924/JSSW.100.9)

### ë¼ì´ì„ ìŠ¤ ë° ì‚¬ìš© ì¡°ê±´

**ë¼ì´ì„ ìŠ¤**: CC BY-NC-SA 4.0 (Creative Commons Attribution-NonCommercial-ShareAlike)

#### âœ… í—ˆìš©ë˜ëŠ” ì‚¬ìš©

**í•™ìˆ  ì—°êµ¬**:
- ë…¼ë¬¸ ì‘ì„± ë° ì¸ìš©
- í•™ìˆ  ë°œí‘œ ë° êµìœ¡
- ì—°êµ¬ ëª©ì  ìˆ˜ì • ë° ê°œì„ 
- ë¹„ì˜ë¦¬ ì—°êµ¬ í”„ë¡œì íŠ¸

**ë¹„ì˜ë¦¬ í™œìš©**:
- êµìœ¡ ê¸°ê´€ì˜ êµì¬ ë° ì‹¤ìŠµ
- ê³µê³µ ê¸°ê´€ì˜ ë””ì§€í„¸ ì•„ì¹´ì´ë¸Œ êµ¬ì¶•
- ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ í†µí•©
- ë¬¸í™”ì¬ ë””ì§€í„¸í™” ì‚¬ì—…

#### âŒ ì œí•œë˜ëŠ” ì‚¬ìš©

**ìƒì—…ì  ì´ìš©**:
- ìœ ë£Œ ì„œë¹„ìŠ¤ ë˜ëŠ” ì œí’ˆ íŒë§¤
- ê¸°ì—…ì˜ ì˜ë¦¬ ëª©ì  í™œìš©
- ìƒì—…ì  ë¼ì´ì„ ìŠ¤ ì¬ë°°í¬
- ê´‘ê³  ìˆ˜ìµ ëª©ì  ì‚¬ìš©

**ìƒì—…ì  ì´ìš© ë¬¸ì˜**: yachagye@naver.com
- ê°œë³„ í˜‘ì˜ë¥¼ í†µí•´ ìƒì—…ì  ë¼ì´ì„ ìŠ¤ ë¶€ì—¬ ê°€ëŠ¥
- ì—°êµ¬ì¬ë‹¨ ì§€ì› í”„ë¡œì íŠ¸ ì„±ê³¼ í™œìš© ê·œì • ì¤€ìˆ˜

#### ğŸ“‹ ì¡°ê±´

1. **ì €ì‘ì í‘œì‹œ** (Attribution): 
   - ì›ì €ì‘ì ë° ì¶œì²˜ ëª…ì‹œ
   - ë…¼ë¬¸ ì¸ìš© í•„ìˆ˜

2. **ë¹„ì˜ë¦¬** (NonCommercial):
   - ìƒì—…ì  ëª©ì  ì‚¬ìš© ê¸ˆì§€
   - ì‚¬ì „ í˜‘ì˜ í•„ìš”

3. **ë™ì¼ ì¡°ê±´ ë³€ê²½ í—ˆë½** (ShareAlike):
   - íŒŒìƒ ì €ì‘ë¬¼ë„ ê°™ì€ ë¼ì´ì„ ìŠ¤ ì ìš©
   - ì˜¤í”ˆì†ŒìŠ¤ ì •ì‹  ê³„ìŠ¹

**ì „ì²´ ë¼ì´ì„ ìŠ¤ ì¡°ë¬¸**: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode

### í–¥í›„ ê°œì„  ê³¼ì œ

ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ í–¥í›„ ì—°êµ¬ ë°©í–¥:

1. **ì´ì¤‘ ê²½ë¡œ êµ¬ì¡° (Two-Track System)**
   - ìŒ êµ¬ì¡° í‘œì (ã€Šã€‹) ì„±ëŠ¥ ê°œì„ 
   - ì¥ê±°ë¦¬ ì˜ì¡´ì„± ëª¨ë¸ë§ ê°•í™”

2. **ë¬¸í—Œ ìœ í˜•ë³„ ì ì‘í˜• ëª¨ë“ˆ**
   - ë„ë©”ì¸ë³„ íŠ¹í™” ë¯¸ì„¸ì¡°ì •
   - ì¥ë¥´ ì ì‘í˜• ì•„í‚¤í…ì²˜

3. **ë‹¤ì¤‘ê³¼ì œ í†µí•©**
   - ë¬¸ì¥ êµ¬ì¡° ë¶„ì„ê³¼ì˜ ê²°í•©
   - ê°œì²´ëª… ì¸ì‹(NER) í†µí•©
   - Multi-task Learning êµ¬ì¡°

### ì œí•œ ì‚¬í•­

1. **ìŒ êµ¬ì¡° í‘œì **: ì„œëª… ì¸ìš©ë¶€í˜¸(ã€Šã€‹)ëŠ” F1 ~0.73ìœ¼ë¡œ ë‹¤ë¥¸ êµ¬ë‘ì  ëŒ€ë¹„ ë‚®ì€ ì„±ëŠ¥
2. **í¬ì†Œ ë°ì´í„°**: ëŠë‚Œí‘œ(!)ëŠ” í•™ìŠµ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¬í˜„ìœ¨ ì €í•˜
3. **ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸**: 512 í† í° ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ê¸´ í…ìŠ¤íŠ¸ ìë™ ì²˜ë¦¬)
4. **ë„ë©”ì¸ í¸í–¥**: ê³µì‹ ê¸°ë¡ë¬¼ ì¤‘ì‹¬ í•™ìŠµìœ¼ë¡œ ì‚¬ì  ë¬¸í—Œì—ì„œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥

### ë¬¸ì˜

- **ê°œë°œì**: ì–‘ì •í˜„
- **ì´ë©”ì¼**: yachagye@naver.com
- **GitHub**: https://github.com/yachagye/korean-classical-chinese-punctuation
- **Issues**: https://github.com/yachagye/korean-classical-chinese-punctuation/issues
- **ìƒì—…ì  ì´ìš© ë¬¸ì˜**: ì´ë©”ì¼ë¡œ ì‚¬ì „ í˜‘ì˜

### ë©´ì±… ì¡°í•­

ë³¸ í”„ë¡œê·¸ë¨ì˜ êµ¬ë‘ì  ì˜ˆì¸¡ ê²°ê³¼ëŠ” ì™„ë²½í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ í•™ìˆ  ìë£Œ ë˜ëŠ” ì¶œíŒë¬¼ì— ì‚¬ìš©í•˜ì‹¤ ê²½ìš°, ë°˜ë“œì‹œ ì „ë¬¸ê°€ì˜ ê²€í† ë¥¼ ê±°ì³ ì‚¬ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

---

## <a id="english"></a>English

### Overview

A deep learning model for automatically predicting punctuation marks in Korean Classical Chinese texts. The model predicts 7 types of punctuation marks using collated punctuation texts accumulated through previous research.

**Key Applications**:
- Text preprocessing and normalization
- Index and search system construction
- Translation preprocessing
- OCR post-processing
- Digital humanities research

### Key Features

- **High Accuracy**: F1 Score 0.9110 (v2)
- **Large-scale Training**: 420M characters, 3.4M samples
- **7 Punctuation Types**: , ã€‚ Â· ? ! ã€Š ã€‹
- **Domain-specific**: Supports various genres (chronicles, registers, diaries, collections)
- **Ready-to-use**: GUI executable provided

### Model Versions

| Version | Pre-trained Model | F1 Score | Note |
|---------|------------------|----------|------|
| **v2** | SikuRoBERTa (`SIKU-BERT/sikuroberta`) | **0.9110** | Latest Recommended |
| v1 | Chinese-RoBERTa (`hfl/chinese-roberta-wwm-ext`) | 0.9050 | Published in Paper |

### Performance

**Overall Performance**

| Version | F1 Score | Precision | Recall |
|---------|----------|-----------|--------|
| **v2** | **0.9110** | 0.9117 | 0.9103 |
| v1 | 0.9050 | 0.9057 | 0.9043 |

**Per-punctuation Performance (v1)**

| Punctuation | F1 Score | Precision | Recall |
|-------------|----------|-----------|--------|
| ? | 0.9436 | 0.9419 | 0.9454 |
| , | 0.9127 | 0.9130 | 0.9124 |
| ã€‚ | 0.8818 | 0.9054 | 0.8594 |
| Â· | 0.8759 | 0.9157 | 0.8394 |
| ã€Š | 0.7367 | 0.8155 | 0.6717 |
| ã€‹ | 0.7311 | 0.8024 | 0.6713 |
| ! | 0.6369 | 0.8114 | 0.5241 |

*Detailed v2 per-punctuation performance to be updated*

**Domain-specific Performance (v1)**

| Domain | F1 Score | Data Size (Total Characters) |
|--------|----------|-------------|
| Chronicles | 0.9162 | 30,682,976 |
| Registers | 0.9114 | 1,896,232 |
| Gazetteers | 0.9116 | 501,942 |
| Biographies | 0.8606 | 591,983 |
| Legal Codes | 0.8485 | 907,893 |
| Collections | 0.8354 | 1,885,268 |
| Diaries | 0.8229 | 544,768 |

**External Validation (Unseen Data, v1)**

Performance evaluation on punctuation position matching for unseen data with only sentence markers:

| Dataset | F1 Score | Data Size (Total Characters) | Source |
|---------|----------|------------------------------|--------|
| Korean Literary Collections | 0.8784 | 166,763,095 | ITKC Database |
| Ilseongrok | 0.9065 | 6,743,710 | Kyujanggak Institute for Korean Studies |

### ğŸ“¦ Data and Model Downloads

**Google Drive Public Repository**: https://drive.google.com/drive/folders/1WGueOa8Oz7kqv4ha7_9pgFRKOzXWId2H?usp=drive_link

All training data, models, code, and executables are available for free download.

#### Folder Structure

```
Korean Classical Chinese Punctuation Model/
â”‚
â”œâ”€â”€ Preprocessed Texts/          # Preprocessed texts file (ZIP)
â”‚   â”œâ”€â”€ Miscellaneous.zip
â”‚   â”œâ”€â”€ Registers.zip            
â”‚   â”œâ”€â”€ Collections.zip          
â”‚   â”œâ”€â”€ Legal Codes.zip          
â”‚   â”œâ”€â”€ Chronicles.zip           
â”‚   â”œâ”€â”€ Diaries.zip             
â”‚   â”œâ”€â”€ Biographies.zip         
â”‚   â””â”€â”€ Gazetteers.zip
â”‚
â”œâ”€â”€ Training Data/               # Preprocessed JSONL (ZIP)
â”‚   â”œâ”€â”€ train.zip               # Training data
â”‚   â””â”€â”€ val.zip                 # Validation data
â”‚
â”œâ”€â”€ Models(.ckpt)/              # Trained model checkpoints
â”‚   â”œâ”€â”€ best_model_9050.zip     # v1: F1 0.9050 (Paper version)
â”‚   â””â”€â”€ best_model_9110.zip     # v2: F1 0.9110 (Latest recommended)
â”‚
â”œâ”€â”€ Code/                       # Complete source code
â”‚   â”œâ”€â”€ [Preprocessing Scripts]
â”‚   â”‚   â”œâ”€â”€ 1_1_preprocessing_remove_korean_etc.py
â”‚   â”‚   â”œâ”€â”€ 1_2_preprocessing_convert_26_punctuations.py
â”‚   â”‚   â”œâ”€â”€ 1_3_preprocessing_preserve_chinese_26_punct.py
â”‚   â”‚   â”œâ”€â”€ 1_4_preprocessing_convert_7_punctuations.py
â”‚   â”‚   â”œâ”€â”€ 1_5_preprocessing_remove_unpunctuated_lines.py
â”‚   â”‚   â””â”€â”€ 1_6_preprocessing_remove_duplicate_punct.py
â”‚   â”‚
â”‚   â”œâ”€â”€ [Training Data Generation]
â”‚   â”‚   â”œâ”€â”€ 2_generate_training_data_7punct_jsonl.py
â”‚   â”‚   â””â”€â”€ 3_validate_training_data_7punct_jsonl.py
â”‚   â”‚
â”‚   â”œâ”€â”€ [Model Training and Evaluation]
â”‚   â”‚   â”œâ”€â”€ 4_0_train_punctuation_v1_7punct_ChineseRoBERTa_Lightning.py
â”‚   â”‚   â”œâ”€â”€ 4_0_train_punctuation_v2_7punct_SikuRoBERTa_Lightning.py
â”‚   â”‚   â””â”€â”€ 6_F1_evaluation.py
â”‚   â”‚
â”‚   â””â”€â”€ [Inference and Applications]
â”‚       â”œâ”€â”€ punctuation_7_inference_model.py    # Core inference module
â”‚       â”œâ”€â”€ punctuation_7_process_txt.py       # TXT file processing
â”‚       â”œâ”€â”€ punctuation_7_process_csv.py       # CSV file processing
â”‚       â”œâ”€â”€ punctuation_7_validate_accuracy.py
â”‚       â”œâ”€â”€ build_executable_v1_ChineseRoBERTa.py
â”‚       â””â”€â”€ build_executable_v2_SikuRoBERTa.py
â”‚
â””â”€â”€ Korean Classical Chinese Punctuation Program/
    â”œâ”€â”€ README_v1.0.txt                    # User manual
    â””â”€â”€ ChinesePunctuationInference_v1.0.zip   # Windows executable
        â””â”€â”€ ChinesePunctuationInference.exe
    â”œâ”€â”€ README_v2.0.txt                    # User manual
    â””â”€â”€ ChinesePunctuationInference_v2.0.zip   # Windows executable
        â””â”€â”€ ChinesePunctuationInference_v2.exe
```

#### Download Guide

**1. Executable Only (General Users)**
```
ğŸ“¥ Download: Korean Classical Chinese Punctuation Program/ChinesePunctuationInference_v2.0.zip (v2 recommended)
ğŸ“¦ Size: ~3.6GB
ğŸ’» Purpose: Run directly on Windows (Python not required)
```

**2. Python Code Execution (Developers)**
```
ğŸ“¥ Download: 
   - Code/ folder (all files)
   - Models(.ckpt)/best_model_9110.zip (v2 recommended)
ğŸ’» Usage:
   python punctuation_7_process_txt.py --checkpoint checkpoint.ckpt --input your_file.txt
```

**3. Model Training/Research (AI Researchers)**
```
ğŸ“¥ Download:
   - Training Data/train.zip, val.zip
   - Code/4_0_train_punctuation_v1_7punct_ChineseRoBERTa_Lightning.py (v1)
   - Code/4_0_train_punctuation_v2_7punct_SikuRoBERTa_Lightning.py (v2)
   - Models(.ckpt)/ (for fine-tuning)
ğŸ’» Purpose: Model retraining, fine-tuning, experiments
```

**4. Original Text Research (Historians/Humanists)**
```
ğŸ“¥ Download: Preprocessed Texts/ folder (selected ZIPs)
ğŸ’» Purpose: Data analysis, corpus construction, other research
```

**5. Full Reproduction**
```
ğŸ“¥ Download: All folders
ğŸ’» Purpose: Complete reproduction from raw data to deployment
ğŸ“ Process:
   1. Extract Preprocessed Texts/ ZIPs
   2. Run 6-stage preprocessing scripts
   3. Generate training data (JSONL)
   4. Train model (Lightning)
   5. Evaluation and validation
```

#### Training Data Details

**train.zip when extracted**: `train.jsonl` (~2.5GB)
- Sample count: ~3.4M
- Total characters: ~420M
- Format: JSONL (one sample per line)

**JSONL Structure Example**:
```json
{
  "text": "å¤ªç¥–åº·ç»å¤§ç‹å§“æè«±æˆæ¡‚å­—å›æ™‰",
  "labels": [
    [0,0,0,0,0,0,0],
    [0,0,0,0,0,0,0],
    [1,0,0,0,0,0,0],
    ...
  ],
  "length": 15,
  "source": "Annals of Joseon Dynasty",
  "domain": "Chronicles"
}
```

**labels index**: [,  ã€‚ Â· ? ! ã€Š ã€‹]
- Example: `[1,0,0,0,0,0,0]` = comma (,)
- Example: `[0,1,0,0,0,0,0]` = period (ã€‚)

#### Original Text ZIP Information

| ZIP File | Extracted Size | Main Documents |
|----------|----------------|----------------|
| Chronicles.zip | ~2GB | Annals of Joseon Dynasty, etc. |
| Registers.zip | ~1.5GB | Government registers |
| Diaries.zip | ~1.2GB | Mukjae Diary, etc. |
| Collections.zip | ~1GB | Korean Literary Collections |
| Legal Codes.zip | ~500MB | Gyeongguk Daejeon, etc. |
| Gazetteers.zip | ~300MB | Daedong Jiji, etc. |
| Biographies.zip | ~200MB | Gukjo Inmulgo, etc. |
| Miscellaneous.zip | ~100MB | |

- **Compression format**: UTF-8 encoded TXT files
- **Punctuation**: Original collated punctuation (26 types â†’ converted to 7 types after preprocessing)

### Quick Start

#### Method 1: Windows Executable (Recommended - General Users)

```
1. Download "ChinesePunctuationInference_v2.0.zip" from Google Drive (v2 recommended)
2. Extract ZIP
3. Run ChinesePunctuationInference_v2.exe
4. Select file in GUI â†’ Start processing
```

**Download Link**: [Google Drive](https://drive.google.com/drive/folders/1WGueOa8Oz7kqv4ha7_9pgFRKOzXWId2H?usp=drive_link)

#### Method 2: Python Code Execution (Developers/Researchers)

**Python Code**

```python
from êµ¬ë‘ì 7_ì¶”ë¡ ëª¨ë¸ import PunctuationPredictor

# Load model
predictor = PunctuationPredictor(
    checkpoint_path="path/to/checkpoint.ckpt"
)

# Prediction
text = "å¤ªç¥–åº·ç»å¤§ç‹å§“æè«±æˆæ¡‚å­—å›æ™‰å¤è«±æ—¦è™Ÿæ¾è»’"
result = predictor.predict(text)
print(result)
# Output: å¤ªç¥–åº·ç»å¤§ç‹, å§“æ, è«±æˆæ¡‚, å­—å›æ™‰ã€‚å¤è«±æ—¦, è™Ÿæ¾è»’ã€‚
```

**Note**: Python files use Korean names (e.g., `êµ¬ë‘ì 7_ì¶”ë¡ ëª¨ë¸.py`). The English names in examples are for reference only.

**GUI Executable**

```bash
# Build Windows executable (v1)
python êµ¬ë‘ì _ì§€ì •_ì‹¤í–‰íŒŒì¼_ë¹Œë“œ_v1_ChineseRoBERTa.py

# Build Windows executable (v2)
python êµ¬ë‘ì _ì§€ì •_ì‹¤í–‰íŒŒì¼_ë¹Œë“œ_v2_SikuRoBERTa.py

# Run
./dist/í•œë¬¸êµ¬ë‘ì ì¶”ë¡ .exe
```

### Training Data

**Sources**
- National Institute of Korean History Database (https://db.history.go.kr/)
- Korean Classics Comprehensive DB (https://db.itkc.or.kr/)
- Academy of Korean Studies Digital Library (https://jsg.aks.ac.kr/)

**Scale**
- Total characters: ~420M
- Training samples: ~3.4M
- Data types: 8 genres (chronicles, collections, diaries, registers, legal codes, gazetteers, biographies, etc.)
- Punctuation types: 7 (, ã€‚ Â· ? ! ã€Š ã€‹)

**Preprocessing**
- Collection and refinement of collated punctuation texts
- Standardization to 7 punctuation types
- 6-stage preprocessing pipeline

### Model Architecture

**v2 (Latest Recommended)**
- **Base Model**: SikuRoBERTa (`SIKU-BERT/sikuroberta`)
- **Task**: Multi-label Classification
- **Labels**: 7 punctuation marks
- **Training**:
  - GPU: L40S 48GB
  - Batch Size: 160 (effective)
  - Learning Rate: 2e-5
  - Epochs: 3
  - Mixed Precision: bf16

**v1 (Paper Version)**
- **Base Model**: Chinese-RoBERTa (`hfl/chinese-roberta-wwm-ext`)
- Other settings identical

### Directory Structure
```
korean-classical-chinese-punctuation/
â”œâ”€â”€ preprocessing/           # Preprocessing scripts (1_1 ~ 1_6)
â”œâ”€â”€ data_generation/         # Training data generation (2, 3)
â”œâ”€â”€ training/                # Model training and evaluation (4_0, 6)
â”œâ”€â”€ inference/               # Inference and applications (punctuation_7_*)
â””â”€â”€ build/                   # Executable build scripts
```

### Citation

If you use this model, please cite:

**APA Style:**
```
Yang, J. (2025). Development and Application of a Deep Learningâ€“Based Model 
for Automated Punctuation Inference in Korean Classical Chinese. 
The Korean Journal of History (Yoksahak Yongu), 100, 267-297. 
https://doi.org/10.37924/JSSW.100.9
```

**BibTeX:**
```bibtex
@article{yang2025punctuation,
  title={Development and Application of a Deep Learning--Based Model for Automated Punctuation Inference in Korean Classical Chinese},
  author={Yang, Junghyun},
  journal={The Korean Journal of History (Yoksahak Yongu)},
  volume={100},
  pages={267--297},
  year={2025},
  publisher={Honam Historical Society},
  doi={10.37924/JSSW.100.9}
}
```

**Paper Information:**
- Journal: The Korean Journal of History (Yoksahak Yongu)
- Volume: 100
- Publication: November 30, 2025
- Publisher: Honam Historical Society
- DOI: [10.37924/JSSW.100.9](https://doi.org/10.37924/JSSW.100.9)

### License and Terms of Use

**License**: CC BY-NC-SA 4.0 (Creative Commons Attribution-NonCommercial-ShareAlike)

#### âœ… Permitted Uses

**Academic Research**:
- Paper writing and citation
- Academic presentations and education
- Research-purpose modification and improvement
- Non-profit research projects

**Non-commercial Applications**:
- Educational materials and practice in educational institutions
- Digital archive construction by public institutions
- Open-source project integration
- Cultural heritage digitization projects

#### âŒ Restricted Uses

**Commercial Use**:
- Sale of paid services or products
- Corporate profit-oriented use
- Commercial license redistribution
- Use for advertising revenue

**Commercial Use Inquiries**: yachagye@naver.com
- Commercial licenses can be granted through individual negotiation
- Compliance with Korean Research Foundation project output utilization regulations

#### ğŸ“‹ Conditions

1. **Attribution**: 
   - Must specify original author and source
   - Paper citation required

2. **NonCommercial**:
   - Commercial use prohibited
   - Prior consultation required

3. **ShareAlike**:
   - Derivative works must use same license
   - Continue open-source spirit

**Full License Terms**: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode

### Future Improvements

Future research directions proposed in the paper:

1. **Two-Track System**
   - Improve performance for paired punctuation (ã€Šã€‹)
   - Enhance long-distance dependency modeling

2. **Document Type-Adaptive Modules**
   - Domain-specific fine-tuning
   - Genre-adaptive architecture

3. **Multi-task Integration**
   - Combine with sentence structure analysis
   - Integrate Named Entity Recognition (NER)
   - Multi-task Learning structure

### Limitations

1. **Paired Punctuation**: Title quotation marks (ã€Šã€‹) show lower performance (~F1 0.73) compared to other punctuation
2. **Sparse Data**: Exclamation marks (!) have low recall due to insufficient training data
3. **Model Context**: Processes in 512-token units (automatic handling of long texts via sliding window)
4. **Domain Bias**: Training focused on official records may lead to performance degradation on private documents

### Contact

- **Developer**: Junghyun Yang
- **Email**: yachagye@naver.com
- **GitHub**: https://github.com/yachagye/korean-classical-chinese-punctuation
- **Issues**: https://github.com/yachagye/korean-classical-chinese-punctuation/issues
- **Commercial Use Inquiries**: Prior consultation via email

### Disclaimer

The punctuation prediction results of this program may not be perfect. For important academic materials or publications, please use after expert review.
